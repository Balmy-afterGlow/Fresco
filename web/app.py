import os
import torch
import torchvision.transforms as transforms
from PIL import Image
from flask import Flask, request, render_template, jsonify
from werkzeug.utils import secure_filename
import zipfile
import tempfile
import shutil
import base64
import sys

# Add parent directory to path to import utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from train_v3.utils_ResNet50_enhance import OptimizedCNN

app = Flask(__name__)
app.config["MAX_CONTENT_LENGTH"] = 50 * 1024 * 1024  # 50MB max file size
app.config["UPLOAD_FOLDER"] = "uploads"

# Create upload folder if it doesn't exist
os.makedirs(app.config["UPLOAD_FOLDER"], exist_ok=True)

# Global variable to store the model
model = None
classes = None


def load_model():
    """Load the trained model"""
    global model, classes
    try:
        # è®¾ç½®æ¨¡å‹è·¯å¾„ä¼˜å…ˆçº§åˆ—è¡¨
        base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_paths = [
            os.path.join(base_path, "train_v3", "optimized_model.pth"),
            os.path.join(base_path, "best_model.pth"),
            os.path.join(base_path, "latest_checkpoint.pth"),
        ]

        model_path = None
        for path in model_paths:
            if os.path.exists(path):
                model_path = path
                break

        if model_path is None:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ã€‚è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€å­˜åœ¨æ¨¡å‹æ–‡ä»¶:\n"
                + "\n".join(f"  - {path}" for path in model_paths)
            )

        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        # ä½¿ç”¨map_location='cpu'ä»¥ç¡®ä¿åœ¨æ²¡æœ‰GPUçš„ç¯å¢ƒä¸­ä¹Ÿèƒ½è¿è¡Œ
        checkpoint = torch.load(model_path, map_location="cpu")
        print("æ¨¡å‹æ–‡ä»¶åŠ è½½å®Œæˆ")

        # åˆå§‹åŒ–æ¨¡å‹ï¼Œä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å‚æ•°
        print("åˆå§‹åŒ–æ¨¡å‹æ¶æ„...")
        model = OptimizedCNN(num_classes=36)

        # åŠ è½½æ¨¡å‹æƒé‡
        print("åŠ è½½æ¨¡å‹æƒé‡...")
        model.load_state_dict(checkpoint["model_state_dict"])

        # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
        print("è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼...")
        model.eval()

        # å°è¯•ä½¿ç”¨JITä¼˜åŒ–æ¨¡å‹
        try:
            # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹è¾“å…¥ç”¨äºè¿½è¸ª
            example_input = torch.rand(1, 3, 224, 224)
            # ä½¿ç”¨torch.jit.traceæ¥ä¼˜åŒ–æ¨¡å‹
            model = torch.jit.trace(model, example_input)
            print("æˆåŠŸåº”ç”¨JITä¼˜åŒ–")
        except Exception as jit_error:
            print(f"JITä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å‹: {jit_error}")
            # å¦‚æœJITå¤±è´¥ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨æœªä¼˜åŒ–çš„æ¨¡å‹

        # åŠ è½½ç±»åˆ«åç§°
        base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        dataset_path = os.path.join(base_path, "Dataset", "train")

        if os.path.exists(dataset_path):
            classes = sorted(os.listdir(dataset_path))
        else:
            # å¦‚æœæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„ç±»åˆ«åˆ—è¡¨
            classes = [
                "apple",
                "banana",
                "beetroot",
                "bell pepper",
                "cabbage",
                "capsicum",
                "carrot",
                "cauliflower",
                "chilli pepper",
                "corn",
                "cucumber",
                "eggplant",
                "garlic",
                "ginger",
                "grapes",
                "jalepeno",
                "kiwi",
                "lemon",
                "lettuce",
                "mango",
                "onion",
                "orange",
                "paprika",
                "pear",
                "peas",
                "pineapple",
                "pomegranate",
                "potato",
                "raddish",
                "soy beans",
                "spinach",
                "sweetcorn",
                "sweetpotato",
                "tomato",
                "turnip",
                "watermelon",
            ]
            print("âš ï¸ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„å®šä¹‰ç±»åˆ«åˆ—è¡¨")

        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"ç±»åˆ«æ•°é‡: {len(classes)}")
        return True
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½é”™è¯¯: {e}")
        return False


def predict_image(image_path):
    """Predict a single image"""
    global model, classes

    if model is None:
        print("é”™è¯¯: æ¨¡å‹æœªåŠ è½½")
        return None

    # å®šä¹‰å›¾åƒé¢„å¤„ç†ç®¡é“ - ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    transform = transforms.Compose(
        [
            transforms.Resize((256, 256)),  # è°ƒæ•´å›¾åƒå¤§å°
            transforms.CenterCrop(224),  # ä¸­å¿ƒè£å‰ª
            transforms.ToTensor(),  # è½¬æ¢ä¸ºå¼ é‡
            transforms.Normalize(
                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]
            ),  # æ ‡å‡†åŒ–
        ]
    )

    try:
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None

        # éªŒè¯æ–‡ä»¶å¤§å°
        if os.path.getsize(image_path) > 10 * 1024 * 1024:  # 10MBé™åˆ¶
            print(f"å›¾åƒæ–‡ä»¶è¿‡å¤§: {image_path}")
            return None

        # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
        image = Image.open(image_path).convert("RGB")

        # æ·»åŠ åŸºæœ¬å›¾åƒéªŒè¯
        if image.width < 10 or image.height < 10:
            print(f"å›¾åƒå°ºå¯¸å¤ªå°: {image_path}")
            return None

        # åº”ç”¨å›¾åƒå˜æ¢
        input_tensor = transform(image).unsqueeze(0)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦

        # è¿›è¡Œé¢„æµ‹ï¼Œä½¿ç”¨torch.no_grad()æé«˜æ¨ç†é€Ÿåº¦å¹¶å‡å°‘å†…å­˜ä½¿ç”¨
        with torch.no_grad():
            # æ¨¡å‹æ¨ç†
            output = model(input_tensor)
            # è½¬æ¢ä¸ºæ¦‚ç‡
            probabilities = torch.nn.functional.softmax(output[0], dim=0)
            # è·å–å‰5ä¸ªé¢„æµ‹ç»“æœ
            top_probs, top_indices = torch.topk(probabilities, 5)

        # å°†ç»“æœè½¬æ¢ä¸ºJSONåºåˆ—åŒ–æ ¼å¼
        predictions = []
        for i in range(min(5, len(top_indices))):  # ç¡®ä¿ä¸ä¼šè¶…å‡ºç´¢å¼•
            idx = top_indices[i].item()  # è½¬æ¢ä¸ºPythonæ ‡é‡
            if 0 <= idx < len(classes):  # éªŒè¯ç´¢å¼•èŒƒå›´
                predictions.append(
                    {
                        "class": classes[idx],
                        "probability": float(top_probs[i] * 100),  # è½¬ä¸ºç™¾åˆ†æ¯”
                    }
                )

        return predictions
    except Exception as e:
        print(f"å›¾åƒé¢„æµ‹é”™è¯¯ {image_path}: {e}")
        return None


def image_to_base64(image_path):
    """Convert image to base64 for display in browser"""
    try:
        with open(image_path, "rb") as img_file:
            img_data = img_file.read()
            return base64.b64encode(img_data).decode("utf-8")
    except Exception:
        return None


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/upload", methods=["POST"])
def upload_files():
    if "files" not in request.files:
        return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400

    files = request.files.getlist("files")
    if not files or files[0].filename == "":
        return jsonify({"error": "æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶"}), 400

    results = []
    temp_dir = tempfile.mkdtemp()

    try:
        valid_files = False
        # Process each uploaded file
        for file in files:
            if file and file.filename:
                # Check if it's an image file
                filename = secure_filename(file.filename)
                if not filename.lower().endswith(
                    (".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".webp")
                ):
                    continue

                valid_files = True

                try:
                    # Save file temporarily
                    file_path = os.path.join(temp_dir, filename)
                    file.save(file_path)

                    # Predict
                    predictions = predict_image(file_path)
                    if predictions:
                        # Convert image to base64 for display
                        img_base64 = image_to_base64(file_path)
                        if img_base64:  # ç¡®ä¿å›¾åƒæ­£ç¡®è½¬æ¢
                            results.append(
                                {
                                    "filename": filename,
                                    "image": img_base64,
                                    "predictions": predictions,
                                }
                            )
                except Exception:
                    # å•ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
                    continue

        if not valid_files:
            return jsonify({"error": "æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"}), 400

        if not results:
            return jsonify({"error": "æ— æ³•å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡"}), 400

        return jsonify({"results": results})

    except Exception as e:
        return jsonify({"error": f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}"}), 500

    finally:
        # Clean up temporary directory
        shutil.rmtree(temp_dir, ignore_errors=True)


@app.route("/upload_zip", methods=["POST"])
def upload_zip():
    if "zipfile" not in request.files:
        return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ ZIPæ–‡ä»¶"}), 400

    file = request.files["zipfile"]
    if file.filename == "":
        return jsonify({"error": "æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶"}), 400

    if not file.filename.lower().endswith(".zip"):
        return jsonify({"error": "è¯·ä¸Šä¼ ZIPæ ¼å¼çš„æ–‡ä»¶"}), 400

    results = []
    temp_dir = tempfile.mkdtemp()

    try:
        # Save uploaded zip file
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        file.save(zip_path)

        # Extract zip file
        extract_dir = os.path.join(temp_dir, "extracted")
        os.makedirs(extract_dir, exist_ok=True)

        try:
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                # æ£€æŸ¥å‹ç¼©åŒ…æ˜¯å¦æœ‰æ•ˆ
                if zip_ref.testzip() is not None:
                    return jsonify({"error": "ZIPæ–‡ä»¶å·²æŸå"}), 400

                # å®‰å…¨è§£å‹ç¼©
                for member in zip_ref.infolist():
                    # è·³è¿‡éšè—æ–‡ä»¶å’Œç›®å½•
                    if member.filename.startswith(
                        "__MACOSX"
                    ) or member.filename.startswith("."):
                        continue
                    # è·³è¿‡å¤§äº50MBçš„æ–‡ä»¶
                    if member.file_size > 50 * 1024 * 1024:
                        continue
                    # è§£å‹ç¼©
                    zip_ref.extract(member, extract_dir)
        except zipfile.BadZipFile:
            return jsonify({"error": "æ— æ•ˆçš„ZIPæ–‡ä»¶æ ¼å¼"}), 400

        # Find all image files in extracted directory (recursive)
        image_files = []
        for root, dirs, files in os.walk(extract_dir):
            # è·³è¿‡éšè—ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith(".")]

            for filename in files:
                if filename.lower().endswith(
                    (".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".webp")
                ):
                    image_files.append(os.path.join(root, filename))

        if not image_files:
            return jsonify({"error": "ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"}), 400

        # Process each image
        for image_path in image_files:
            try:
                predictions = predict_image(image_path)
                if predictions:
                    # Get relative filename for display
                    rel_filename = os.path.relpath(image_path, extract_dir)
                    img_base64 = image_to_base64(image_path)
                    if img_base64:  # ç¡®ä¿å›¾ç‰‡è½¬æ¢æˆåŠŸ
                        results.append(
                            {
                                "filename": rel_filename,
                                "image": img_base64,
                                "predictions": predictions,
                            }
                        )
            except Exception:
                # å•å¼ å›¾ç‰‡å¤„ç†å¤±è´¥æ—¶ç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
                continue

        if not results:
            return jsonify({"error": "æ— æ³•å¤„ç†ZIPæ–‡ä»¶ä¸­çš„ä»»ä½•å›¾ç‰‡"}), 400

        return jsonify({"results": results})

    except Exception as e:
        return jsonify({"error": f"å¤„ç†ZIPæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}), 500

    finally:
        # Clean up temporary directory
        shutil.rmtree(temp_dir, ignore_errors=True)


if __name__ == "__main__":
    try:
        print("=" * 50)
        print("ğŸ æ°´æœè”¬èœåˆ†ç±»åº”ç”¨æœåŠ¡å™¨")
        print("=" * 50)
        print("ç‰ˆæœ¬: 1.0.0")
        print("æ­£åœ¨åŠ è½½æ·±åº¦å­¦ä¹ æ¨¡å‹...")
        if load_model():
            print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print("-" * 50)
            print("å¯åŠ¨ Flask æœåŠ¡å™¨...")
            print("æœåŠ¡å™¨å°†åœ¨ http://0.0.0.0:5000 ä¸Šè¿è¡Œ")
            print("å¯é€šè¿‡æµè§ˆå™¨è®¿é—® http://localhost:5000")
            print("-" * 50)
            app.run(debug=False, host="0.0.0.0", port=5000)
        else:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚")
            print("è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„å­˜åœ¨æ¨¡å‹æ–‡ä»¶:")
            print("  - /home/moyu/Code/Project/Fresco/train_v3/optimized_model.pth")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å™¨å·²ç»ˆæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨æœåŠ¡å™¨æ—¶å‡ºé”™: {str(e)}")
        sys.exit(1)
